{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a51cf303-10f8-4192-823b-f6c25d2cd668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 163 entries, 0 to 162\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   diary_entry  163 non-null    object\n",
      " 1   used         49 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.7+ KB\n",
      "None\n",
      "                                         diary_entry used\n",
      "0  As soon as I heard that Jimmy O. Yang was doin...    y\n",
      "1  It’s already been two years since I started le...    y\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "myfile=\"test-created-164.csv\"\n",
    "mydata = pd.read_csv(myfile)\n",
    "print(mydata.info())\n",
    "print(mydata.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda015ab-e0f1-472f-8442-317982e389ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"#####\"\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def get_json(content):\n",
    "    #get json part\n",
    "    json_text = re.search(r'\\{.*\\}', content, re.DOTALL)\n",
    "    # check json data\n",
    "    if json_text:\n",
    "        myjson = json_text.group()\n",
    "        #print(\"Extracted JSON:\", myjson)  # check extracted json\n",
    "        try:\n",
    "            data = json.loads(myjson)  # JSON parsing\n",
    "            return data\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"[jp] JSON parsing error:\", e)\n",
    "    else:\n",
    "        print(\"[jp] JSON data not found\")\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def analyze_emotions(system_content,user_content):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_content\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_content\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    answer = response.choices[0].message.content #get json response\n",
    "    return get_json(answer)\n",
    "\n",
    "system_content = \"\"\"\n",
    "You will analyze the diary entry based on the 6 core emotions in psychology: joy, sadness, anger, fear, disgust, surprise. Each emotion's intensity will be rated on a scale of 1 to 5 as follows:\n",
    "1 - very weak (barely felt)\n",
    "2 - weak (slightly felt)\n",
    "3 - moderate (moderately felt)\n",
    "4 - strong (strongly felt)\n",
    "5 - very strong (very strongly felt)\n",
    "Please respond strictly in JSON format with the following structure:\n",
    "\n",
    "{\n",
    "  \"diary_entry\": \"...\",\n",
    "  \"joy\": ...,\n",
    "  \"sadness\": ...,\n",
    "  \"anger\": ...,\n",
    "  \"fear\": ...,\n",
    "  \"disgust\": ...,\n",
    "  \"surprise\": ...\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "user_content=\"\"\"\n",
    "Diary_entry=\"It is 8pm and I have no idea when I am going home. I also need to check my parking meter.\"\n",
    "\"\"\"\n",
    "\n",
    "#json_result = analyze_emotions(system_content,user_content)\n",
    "#print(json_result)\n",
    "#print(json_result['anger'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "419ca932-1383-43a1-a88d-655b36335a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0\n",
      "Index: 1\n",
      "Index: 2\n",
      "Index: 3\n",
      "Index: 4\n",
      "Index: 5\n",
      "Index: 6\n",
      "Index: 7\n",
      "Index: 8\n",
      "Index: 9\n",
      "Index: 10\n",
      "Index: 11\n",
      "Index: 12\n",
      "Index: 13\n",
      "Index: 14\n",
      "Index: 15\n",
      "Index: 16\n",
      "Index: 17\n",
      "Index: 18\n",
      "Index: 19\n",
      "Index: 20\n",
      "Index: 21\n",
      "Index: 22\n",
      "Index: 23\n",
      "Index: 24\n",
      "Index: 25\n",
      "Index: 26\n",
      "Index: 27\n",
      "Index: 28\n",
      "Index: 29\n",
      "Index: 30\n",
      "Index: 31\n",
      "Index: 32\n",
      "Index: 33\n",
      "Index: 34\n",
      "Index: 35\n",
      "Index: 36\n",
      "Index: 37\n",
      "Index: 38\n",
      "Index: 39\n",
      "Index: 40\n",
      "Index: 41\n",
      "Index: 42\n",
      "Index: 43\n",
      "Index: 44\n",
      "Index: 45\n",
      "Index: 46\n",
      "Index: 47\n",
      "Index: 48\n",
      "Index: 49\n",
      "Index: 50\n",
      "Index: 51\n",
      "Index: 52\n",
      "Index: 53\n",
      "Index: 54\n",
      "Index: 55\n",
      "Index: 56\n",
      "Index: 57\n",
      "Index: 58\n",
      "Index: 59\n",
      "Index: 60\n",
      "Index: 61\n",
      "Index: 62\n",
      "Index: 63\n",
      "Index: 64\n",
      "Index: 65\n",
      "Index: 66\n",
      "Index: 67\n",
      "Index: 68\n",
      "Index: 69\n",
      "Index: 70\n",
      "Index: 71\n",
      "Index: 72\n",
      "Index: 73\n",
      "Index: 74\n",
      "Index: 75\n",
      "Index: 76\n",
      "Index: 77\n",
      "Index: 78\n",
      "Index: 79\n",
      "Index: 80\n",
      "Index: 81\n",
      "Index: 82\n",
      "Index: 83\n",
      "Index: 84\n",
      "Index: 85\n",
      "Index: 86\n",
      "Index: 87\n",
      "Index: 88\n",
      "Index: 89\n",
      "Index: 90\n",
      "Index: 91\n",
      "Index: 92\n",
      "Index: 93\n",
      "Index: 94\n",
      "Index: 95\n",
      "Index: 96\n",
      "Index: 97\n",
      "Index: 98\n",
      "Index: 99\n",
      "Index: 100\n",
      "Index: 101\n",
      "Index: 102\n",
      "Index: 103\n",
      "Index: 104\n",
      "Index: 105\n",
      "Index: 106\n",
      "Index: 107\n",
      "Index: 108\n",
      "Index: 109\n",
      "Index: 110\n",
      "Index: 111\n",
      "Index: 112\n",
      "Index: 113\n",
      "Index: 114\n",
      "Index: 115\n",
      "Index: 116\n",
      "Index: 117\n",
      "Index: 118\n",
      "Index: 119\n",
      "Index: 120\n",
      "Index: 121\n",
      "Index: 122\n",
      "Index: 123\n",
      "Index: 124\n",
      "Index: 125\n",
      "Index: 126\n",
      "Index: 127\n",
      "Index: 128\n",
      "Index: 129\n",
      "Index: 130\n",
      "Index: 131\n",
      "Index: 132\n",
      "Index: 133\n",
      "Index: 134\n",
      "Index: 135\n",
      "Index: 136\n",
      "Index: 137\n",
      "Index: 138\n",
      "Index: 139\n",
      "Index: 140\n",
      "Index: 141\n",
      "Index: 142\n",
      "Index: 143\n",
      "Index: 144\n",
      "Index: 145\n",
      "Index: 146\n",
      "Index: 147\n",
      "Index: 148\n",
      "Index: 149\n",
      "Index: 150\n",
      "Index: 151\n",
      "Index: 152\n",
      "Index: 153\n",
      "Index: 154\n",
      "Index: 155\n",
      "Index: 156\n",
      "Index: 157\n",
      "Index: 158\n",
      "Index: 159\n",
      "Index: 160\n",
      "Index: 161\n",
      "Index: 162\n",
      "                                         diary_entry used  joy  sadness  \\\n",
      "0  As soon as I heard that Jimmy O. Yang was doin...    y  5.0      1.0   \n",
      "1  It’s already been two years since I started le...    y  4.0      2.0   \n",
      "2  I can’t understand why Sarah acted that way. I...    y  1.0      3.0   \n",
      "3  I heard a few weeks ago that Squid Game 2 was ...    y  1.0      2.0   \n",
      "4  Today started well with a quiet morning and a ...    y  3.0      3.0   \n",
      "\n",
      "   anger  fear  disgust  surprise  \n",
      "0    1.0   3.0      1.0       3.0  \n",
      "1    1.0   2.0      1.0       3.0  \n",
      "2    4.0   2.0      3.0       2.0  \n",
      "3    3.0   1.0      3.0       2.0  \n",
      "4    2.0   2.0      2.0       2.0  \n"
     ]
    }
   ],
   "source": [
    "# 각 감정의 컬럼 이름\n",
    "emotion_columns = [\"joy\", \"sadness\", \"anger\", \"fear\", \"disgust\", \"surprise\"]\n",
    "\n",
    "# 각 diary_entry에 대해 감정 분석을 수행하고 결과 업데이트\n",
    "for index, row in mydata.iterrows():\n",
    "    print(f\"Index: {index}\")\n",
    "    \n",
    "    # 감정 분석 함수 호출\n",
    "    json_result = analyze_emotions(system_content, row['diary_entry'])\n",
    "    \n",
    "    # JSON 결과에서 각 감정의 강도를 추출하여 data DataFrame에 업데이트\n",
    "    for emotion in emotion_columns:\n",
    "        if emotion in json_result:\n",
    "            mydata.at[index, emotion] = json_result[emotion]\n",
    "        else:\n",
    "            # json_result에 해당 감정이 없을 경우 기본값으로 0 설정\n",
    "            mydata.at[index, emotion] = 0\n",
    "    #print(mydata.loc[index])\n",
    "\n",
    "# 업데이트된 DataFrame 확인\n",
    "print(mydata.head())\n",
    "# 업데이트된 DataFrame을 CSV 파일로 저장\n",
    "mydata.to_csv(f'{myfile}-answer-created-2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85b8a881-5abb-4f9d-b8f4-6189e6b0a51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0\n",
      "{'diary_entry': 'As soon as I heard that Jimmy O. Yang was doing a nationwide tour in March, I booked my ticket right away. There are still a few months left, but I’m so excited that I watch his shorts every day—it already seems like it’s going to be fun. But I’m worried there might not be any parking spots nearby. Not having a place to park would be such a hassle. Oh well, let’s just think positive!', 'joy': 4, 'sadness': 1, 'anger': 1, 'fear': 2, 'disgust': 1, 'surprise': 3}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m json_result \u001b[38;5;241m=\u001b[39m analyze_emotions(system_content, row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiary_entry\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(json_result)\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28minput\u001b[39m()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# JSON 결과에서 각 감정의 강도를 추출하여 data DataFrame에 업데이트\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m emotion \u001b[38;5;129;01min\u001b[39;00m emotion_columns:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py:1262\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1260\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_request(\n\u001b[1;32m   1263\u001b[0m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[1;32m   1264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_ident[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1266\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1267\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py:1305\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1304\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1307\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# 각 감정의 컬럼 이름\n",
    "emotion_columns = [\"joy\", \"sadness\", \"anger\", \"fear\", \"disgust\", \"surprise\"]\n",
    "\n",
    "# 각 diary_entry에 대해 감정 분석을 수행하고 결과 업데이트\n",
    "for index, row in mydata.iterrows():\n",
    "    print(f\"Index: {index}\")\n",
    "    \n",
    "    # 감정 분석 함수 호출\n",
    "    json_result = analyze_emotions(system_content, row['diary_entry'])\n",
    "    print(json_result)\n",
    "    input()\n",
    "    \n",
    "    # JSON 결과에서 각 감정의 강도를 추출하여 data DataFrame에 업데이트\n",
    "    for emotion in emotion_columns:\n",
    "        if emotion in json_result:\n",
    "            mydata.at[index, emotion] = json_result[emotion]\n",
    "        else:\n",
    "            # json_result에 해당 감정이 없을 경우 기본값으로 0 설정\n",
    "            mydata.at[index, emotion] = 0\n",
    "    #print(mydata.loc[index])\n",
    "\n",
    "# 업데이트된 DataFrame 확인\n",
    "print(mydata.head())\n",
    "# 업데이트된 DataFrame을 CSV 파일로 저장\n",
    "mydata.to_csv(f'{myfile}-answer-created-2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d6f5c8-aed9-4e88-a00e-c2dbc193ec6d",
   "metadata": {},
   "source": [
    "# Negative Answer Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fc1b71-181f-464d-a1a4-e58b464e3f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                        diary_entry  joy  \\\n",
      "0           0  As soon as I heard that Jimmy O. Yang was doin...    5   \n",
      "1           1  It’s already been two years since I started le...    4   \n",
      "2           2  I can’t understand why Sarah acted that way. I...    1   \n",
      "3           3  I heard a few weeks ago that Squid Game 2 was ...    1   \n",
      "4           4  Today started well with a quiet morning and a ...    3   \n",
      "\n",
      "   sadness  anger  fear  disgust  surprise  \\\n",
      "0        1      1     3        1         3   \n",
      "1        2      1     2        1         3   \n",
      "2        3      4     2        3         2   \n",
      "3        2      3     1        3         2   \n",
      "4        3      2     2        2         2   \n",
      "\n",
      "                                negative_diary_entry  \n",
      "0  When I heard that Jimmy O. Yang was doing a na...  \n",
      "1  It's been a depressing two years since I start...  \n",
      "2  I am beyond frustrated with Sarah. I explicitl...  \n",
      "3  I heard a few weeks ago that Squid Game 2 was ...  \n",
      "4  Today was a dull beginning, despite starting w...  \n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "                                negative_diary_entry  joy  sadness  anger  \\\n",
      "0  When I heard that Jimmy O. Yang was doing a na...    1        2      3   \n",
      "1  It's been a depressing two years since I start...    1        4      2   \n",
      "2  I am beyond frustrated with Sarah. I explicitl...    1        3      5   \n",
      "3  I heard a few weeks ago that Squid Game 2 was ...    1        2      4   \n",
      "4  Today was a dull beginning, despite starting w...    1        3      3   \n",
      "\n",
      "   fear  disgust  surprise  \n",
      "0     3        2         1  \n",
      "1     4        2         1  \n",
      "2     2        3         2  \n",
      "3     2        5         3  \n",
      "4     2        2         1  \n",
      "[jp] 감정 분석 결과가 analyzed_emotions.csv에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file = \"diary_negative_entries.csv\"\n",
    "data = pd.read_csv(file)\n",
    "\n",
    "print(data.head())\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"#####\"\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def get_json(content):\n",
    "    #get json part\n",
    "    json_text = re.search(r'\\{.*\\}', content, re.DOTALL)\n",
    "    # check json data\n",
    "    if json_text:\n",
    "        myjson = json_text.group()\n",
    "        #print(\"Extracted JSON:\", myjson)  # check extracted json\n",
    "        try:\n",
    "            data = json.loads(myjson)  # JSON parsing\n",
    "            return data\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"[jp] JSON parsing error:\", e)\n",
    "    else:\n",
    "        print(\"[jp] JSON data not found\")\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def analyze_emotions(system_content,user_content):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_content\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_content\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    answer = response.choices[0].message.content #get json response\n",
    "    return get_json(answer)\n",
    "\n",
    "system_content = \"\"\"\n",
    "You will analyze the diary entry based on the 6 core emotions in psychology: joy, sadness, anger, fear, disgust, surprise. Each emotion's intensity will be rated on a scale of 1 to 5 as follows:\n",
    "1 - very weak (barely felt)\n",
    "2 - weak (slightly felt)\n",
    "3 - moderate (moderately felt)\n",
    "4 - strong (strongly felt)\n",
    "5 - very strong (very strongly felt)\n",
    "Please respond strictly in JSON format with the following structure:\n",
    "\n",
    "{\n",
    "  \"diary_entry\": \"...\",\n",
    "  \"joy\": ...,\n",
    "  \"sadness\": ...,\n",
    "  \"anger\": ...,\n",
    "  \"fear\": ...,\n",
    "  \"disgust\": ...,\n",
    "  \"surprise\": ...\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "user_content=\"\"\"\n",
    "Diary_entry=\"It is 8pm and I have no idea when I am going home. I also need to check my parking meter.\"\n",
    "\"\"\"\n",
    "\n",
    "#json_result = analyze_emotions(system_content,user_content)\n",
    "#print(json_result)\n",
    "#print(json_result['anger'])\n",
    "\n",
    "#from data get 'negative_diary_entry' column and get emotion value from using analyze emotions for each diary entry\n",
    "# and save 'negative_diary_entry','joy','sadness','anger','fear','disgust','surprise' column and values and save it to file\n",
    "\n",
    "# 새로운 DataFrame 생성\n",
    "results = []\n",
    "i=0\n",
    "# negative_diary_entry 열에서 각 일기를 처리\n",
    "for entry in data['negative_diary_entry']:\n",
    "    i=i+1\n",
    "    print(i)\n",
    "    user_content = f\"\"\"\n",
    "    Diary_entry=\"{entry}\"\n",
    "    \"\"\"\n",
    "    json_result = analyze_emotions(system_content, user_content)  # 감정 분석 수행\n",
    "    \n",
    "    if json_result:  # JSON 결과가 있으면 처리\n",
    "        results.append({\n",
    "            \"negative_diary_entry\": entry,\n",
    "            \"joy\": json_result.get(\"joy\", 0),\n",
    "            \"sadness\": json_result.get(\"sadness\", 0),\n",
    "            \"anger\": json_result.get(\"anger\", 0),\n",
    "            \"fear\": json_result.get(\"fear\", 0),\n",
    "            \"disgust\": json_result.get(\"disgust\", 0),\n",
    "            \"surprise\": json_result.get(\"surprise\", 0)\n",
    "        })\n",
    "\n",
    "# 결과를 DataFrame으로 변환\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# DataFrame 확인\n",
    "print(results_df.head())\n",
    "\n",
    "# CSV 파일로 저장\n",
    "output_file = \"analyzed_emotions.csv\"\n",
    "results_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"[jp] 감정 분석 결과가 {output_file}에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6447dc66-8a9f-43e4-aa5b-d9440f66b114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26b3868-bb85-4c32-b114-463725fba5bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
